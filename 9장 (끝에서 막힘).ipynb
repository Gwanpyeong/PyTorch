{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26e96a0f-bb91-4366-b92a-ff4385618d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: click in c:\\users\\516-29\\anaconda3\\envs\\ddd\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\516-29\\anaconda3\\envs\\ddd\\lib\\site-packages (from nltk) (1.5.2)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Using cached regex-2025.11.3-cp39-cp39-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tqdm (from nltk)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\516-29\\anaconda3\\envs\\ddd\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Using cached nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "Using cached regex-2025.11.3-cp39-cp39-win_amd64.whl (277 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, nltk\n",
      "\n",
      "   ------------- -------------------------- 1/3 [regex]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   ---------------------------------------- 3/3 [nltk]\n",
      "\n",
      "Successfully installed nltk-3.9.2 regex-2025.11.3 tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea8a3614-e0df-47f7-988c-a0451f9dfac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\users\\516-29\\jpype1-1.3.0-cp39-cp39-win_amd64.whl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Requirement 'JPype1-1.3.0-cp39-cp39-win_amd64.whl' looks like a filename, but the file does not exist\n",
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\516-29\\\\JPype1-1.3.0-cp39-cp39-win_amd64.whl'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install JPype1-1.3.0-cp39-cp39-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80520103-b813-456a-88df-b946bf55f298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting konlpy\n",
      "  Using cached konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting JPype1>=0.7.0 (from konlpy)\n",
      "  Using cached jpype1-1.6.0-cp39-cp39-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting lxml>=4.1.0 (from konlpy)\n",
      "  Using cached lxml-6.0.2-cp39-cp39-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\users\\516-29\\anaconda3\\envs\\ddd\\lib\\site-packages (from konlpy) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\516-29\\anaconda3\\envs\\ddd\\lib\\site-packages (from JPype1>=0.7.0->konlpy) (25.0)\n",
      "Using cached konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
      "Using cached jpype1-1.6.0-cp39-cp39-win_amd64.whl (356 kB)\n",
      "Using cached lxml-6.0.2-cp39-cp39-win_amd64.whl (4.0 MB)\n",
      "Installing collected packages: lxml, JPype1, konlpy\n",
      "\n",
      "   ---------------------------------------- 0/3 [lxml]\n",
      "   -------------------------- ------------- 2/3 [konlpy]\n",
      "   ---------------------------------------- 3/3 [konlpy]\n",
      "\n",
      "Successfully installed JPype1-1.6.0 konlpy-0.6.0 lxml-6.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "035a404f-44dd-4e38-a0a5-b15b91bcb58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\516-29\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\516-29\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\516-29\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\516-29\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\516-29\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\516-29\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\516-29\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\516-29\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\516-29\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\516-29\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\516-29\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\516-29\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\516-29\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\516-29\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\516-29\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\516-29\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\516-29\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\516-29\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\516-29\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\516-29\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\516-29\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\516-29\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Is', 'it', 'possible', 'distinguishing', 'cats', 'and', 'dogs']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"popular\")\n",
    "text=nltk.word_tokenize(\"Is it possible distinguishing cats and dogs\")\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c43a0fb-4da3-49b4-905a-9a85514a1692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\516-29\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1dbc264-6c75-4d49-b553-f0b8477b0e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Is', 'VBZ'),\n",
       " ('it', 'PRP'),\n",
       " ('possible', 'JJ'),\n",
       " ('distinguishing', 'VBG'),\n",
       " ('cats', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('dogs', 'NNS')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e480934a-e8ad-4817-bb34-8790d54550fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\516-29\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['my', 'favorite', 'subject', 'is', 'math']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "string1=\"my favorite subject is math\"\n",
    "string2=\"my favorite subject is math, english, economic and computer science\"\n",
    "nltk.word_tokenize(string1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31179ba6-cf9c-4943-bd42-271759defaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my',\n",
       " 'favorite',\n",
       " 'subject',\n",
       " 'is',\n",
       " 'math',\n",
       " ',',\n",
       " 'english',\n",
       " ',',\n",
       " 'economic',\n",
       " 'and',\n",
       " 'computer',\n",
       " 'science']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(string2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd6ad1f3-a9be-43ce-805f-7c174ffe0965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in c:\\users\\516-29\\anaconda3\\envs\\ddd\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in c:\\users\\516-29\\anaconda3\\envs\\ddd\\lib\\site-packages (from konlpy) (1.6.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\users\\516-29\\anaconda3\\envs\\ddd\\lib\\site-packages (from konlpy) (6.0.2)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\users\\516-29\\anaconda3\\envs\\ddd\\lib\\site-packages (from konlpy) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\516-29\\anaconda3\\envs\\ddd\\lib\\site-packages (from JPype1>=0.7.0->konlpy) (25.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8e9528a-36e0-4926-878f-4ec3870ca22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['딥러닝이', '쉽', '나요', '?', '어렵', '나요', '?']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran\n",
    "komoran = Komoran()\n",
    "print(komoran.morphs('딥러닝이 쉽나요? 어렵나요?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc5e54b8-5612-4d05-a8ef-b794032bc556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('소파', 'NNP'), ('위', 'NNG'), ('에', 'JKB'), ('있', 'VV'), ('는', 'ETM'), ('것', 'NNB'), ('이', 'JKS'), ('고양이', 'NNG'), ('이', 'VCP'), ('ㄴ가요', 'EF'), ('?', 'SF'), ('강아지', 'NNG'), ('이', 'VCP'), ('ㄴ가요', 'EF'), ('?', 'SF')]\n"
     ]
    }
   ],
   "source": [
    "print(komoran.pos('소파 위에 있는 것이 고양이인가요? 강아지인가요?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67dae8f9-793f-41b6-974b-ed50c28d0e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.4.0-cp39-cp39-win_amd64.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\516-29\\anaconda3\\envs\\ddd\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\516-29\\anaconda3\\envs\\ddd\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Collecting smart_open>=1.8.1 (from gensim)\n",
      "  Using cached smart_open-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\516-29\\anaconda3\\envs\\ddd\\lib\\site-packages (from smart_open>=1.8.1->gensim) (1.17.3)\n",
      "Downloading gensim-4.4.0-cp39-cp39-win_amd64.whl (24.4 MB)\n",
      "   ---------------------------------------- 0.0/24.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/24.4 MB 6.3 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 3.1/24.4 MB 8.4 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 6.0/24.4 MB 10.0 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 9.7/24.4 MB 12.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 14.2/24.4 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 18.9/24.4 MB 15.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.1/24.4 MB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.4/24.4 MB 15.5 MB/s  0:00:01\n",
      "Using cached smart_open-7.5.0-py3-none-any.whl (63 kB)\n",
      "Installing collected packages: smart_open, gensim\n",
      "\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   ---------------------------------------- 2/2 [gensim]\n",
      "\n",
      "Successfully installed gensim-4.4.0 smart_open-7.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdbde4e4-1b0f-42de-b732-73cfb266d605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>tissue</th>\n",
       "      <th>class</th>\n",
       "      <th>class2</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mdb000</td>\n",
       "      <td>C</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>N</td>\n",
       "      <td>535.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mdb001</td>\n",
       "      <td>A</td>\n",
       "      <td>CIRA</td>\n",
       "      <td>N</td>\n",
       "      <td>433.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>mdb002</td>\n",
       "      <td>A</td>\n",
       "      <td>CIRA</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>mdb003</td>\n",
       "      <td>C</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>mdb004</td>\n",
       "      <td>F</td>\n",
       "      <td>CIRF</td>\n",
       "      <td>I</td>\n",
       "      <td>488.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>mdb005</td>\n",
       "      <td>F</td>\n",
       "      <td>CIRF</td>\n",
       "      <td>B</td>\n",
       "      <td>544.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      id tissue class class2      x      y      r\n",
       "0           0  mdb000      C  CIRC      N  535.0  475.0  192.0\n",
       "1           1  mdb001      A  CIRA      N  433.0  268.0   58.0\n",
       "2           2  mdb002      A  CIRA      I    NaN    NaN    NaN\n",
       "3           3  mdb003      C  CIRC      B    NaN    NaN    NaN\n",
       "4           4  mdb004      F  CIRF      I  488.0  145.0   29.0\n",
       "5           5  mdb005      F  CIRF      B  544.0  178.0   26.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C:/Users/516-29/deep/chap09/data/class2.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f08a358-9360-4702-8ebb-5bdfb6e5f295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "id            0\n",
       "tissue        0\n",
       "class         0\n",
       "class2        0\n",
       "x             2\n",
       "y             2\n",
       "r             2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2bf494c-1fcc-49c2-8d0c-8b6b71bdc5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0.000000\n",
       "id            0.000000\n",
       "tissue        0.000000\n",
       "class         0.000000\n",
       "class2        0.000000\n",
       "x             0.333333\n",
       "y             0.333333\n",
       "r             0.333333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81a6b07a-71bb-48fe-bc05-437ca9942b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bd003f2-440a-4ee4-ab10-8ac6efc7ed10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0      id tissue class class2      x      y      r\n",
      "0           0  mdb000      C  CIRC      N  535.0  475.0  192.0\n",
      "1           1  mdb001      A  CIRA      N  433.0  268.0   58.0\n",
      "2           2  mdb002      A  CIRA      I    NaN    NaN    NaN\n",
      "3           3  mdb003      C  CIRC      B    NaN    NaN    NaN\n",
      "4           4  mdb004      F  CIRF      I  488.0  145.0   29.0\n",
      "5           5  mdb005      F  CIRF      B  544.0  178.0   26.0\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d67bbe4e-8f73-4470-804d-6d2262665423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0      id tissue class class2      x      y      r\n",
      "0           0  mdb000      C  CIRC      N  535.0  475.0  192.0\n",
      "1           1  mdb001      A  CIRA      N  433.0  268.0   58.0\n",
      "4           4  mdb004      F  CIRF      I  488.0  145.0   29.0\n",
      "5           5  mdb005      F  CIRF      B  544.0  178.0   26.0\n"
     ]
    }
   ],
   "source": [
    "df1 = df.dropna()\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c56629ed-5c13-4863-b1f4-6010243a41d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0      id tissue class class2      x      y      r\n",
      "0           0  mdb000      C  CIRC      N  535.0  475.0  192.0\n",
      "1           1  mdb001      A  CIRA      N  433.0  268.0   58.0\n",
      "2           2  mdb002      A  CIRA      I    0.0    0.0    0.0\n",
      "3           3  mdb003      C  CIRC      B    0.0    0.0    0.0\n",
      "4           4  mdb004      F  CIRF      I  488.0  145.0   29.0\n",
      "5           5  mdb005      F  CIRF      B  544.0  178.0   26.0\n"
     ]
    }
   ],
   "source": [
    "df2 = df.fillna(0)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad5e87c7-def3-4f84-8b44-cd505b0a2969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0      id tissue class class2      x      y      r\n",
      "0           0  mdb000      C  CIRC      N  535.0  475.0  192.0\n",
      "1           1  mdb001      A  CIRA      N  433.0  268.0   58.0\n",
      "2           2  mdb002      A  CIRA      I  500.0    NaN    NaN\n",
      "3           3  mdb003      C  CIRC      B  500.0    NaN    NaN\n",
      "4           4  mdb004      F  CIRF      I  488.0  145.0   29.0\n",
      "5           5  mdb005      F  CIRF      B  544.0  178.0   26.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\516-29\\AppData\\Local\\Temp\\ipykernel_20744\\4234141631.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['x'].fillna(df['x'].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df['x'].fillna(df['x'].mean(), inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22ddacb5-3fa2-423d-93a9-b8b9fd307079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural Language Processing, or NLP, is the process of extracting the meaning, or intent, behind human language.', 'In the field of Conversational artificial intelligence (AI), NLP allows machines and applications to understand the intent of human language inputs, and then generate appropriate responses, resulting in a natural conversation flow.']\n"
     ]
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "text_sample = 'Natural Language Processing, or NLP, is the process of extracting the meaning, or intent, behind human language. In the field of Conversational artificial intelligence (AI), NLP allows machines and applications to understand the intent of human language inputs, and then generate appropriate responses, resulting in a natural conversation flow.'\n",
    "tokenized_sentences = sent_tokenize(text_sample)\n",
    "print(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc353e56-ef20-46b2-87c6-270b0b6077c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'book', 'is', 'for', 'deep', 'learning', 'learners']\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "sentence = \"This book is for deep learning learners\"\n",
    "words = word_tokenize(sentence)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af210417-c248-4052-996e-23ef8f635f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', \"'\", 's', 'nothing', 'that', 'you', 'don', \"'\", 't', 'already', 'know', 'except', 'most', 'people', 'aren', \"'\", 't', 'aware', 'of', 'how', 'their', 'inner', 'world', 'works', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "sentence = \"it's nothing that you don't already know except most people aren't aware of how their inner world works.\"\n",
    "words = WordPunctTokenizer().tokenize(sentence)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bac7c5aa-9afd-4dcd-803b-4f8ea6ec5585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from konlpy.tag import Okt\n",
    "from gensim.models import word2vec\n",
    "\n",
    "f = open(r'C:/Users/516-29/deep/chap09/data/ratings_train.txt', 'r', encoding='utf-8')\n",
    "rdr = csv.reader(f, delimiter='\\t')\n",
    "rdw = list(rdr)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f997cf7b-0fa8-4bf9-9652-ddebaa55dba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document\n",
      "아 더빙 진짜 짜증나다 목소리\n",
      "흠 포스터 보고 초딩 영화 줄 오버 연기 가볍다 않다\n",
      "너 무재 밓었 다그 래서 보다 추천 다\n",
      "교도소 이야기 구먼 솔직하다 재미 없다 평점 조정\n",
      "사이 몬페 그 의 익살스럽다 연기 돋보이다 영화 스파이더맨 늙다 보이다 하다 커스틴 던스트 너무나도 이쁘다 보이다\n",
      "막 걸음 마 떼다 3 세 초등학교 1 학년 생인 8 살다 영화 ㅋㅋㅋ 별 반개 아깝다 움\n",
      "원작 긴장감 제대로 살리다 하다\n",
      "별 반개 아깝다 욕 나오다 이응경 길용우 연 기 생활 몇 년 정말 발 해도 그것 낫다 납치 감금 반복 반복 이 드라마 가족 없다 연기 못 하다 사람 모 엿 네\n",
      "액션 없다 재미 있다 몇 안되다 영화\n",
      "왜 이렇게 평점 낮다 꽤 볼 한 데 헐리우드 식 화려하다 너무 길들이다 있다\n",
      "걍 인피니트 짱 진짜 짱 ♥\n",
      "볼때 눈물나다 죽다 90년 대의 향수 자극 허진호 감성 절제 멜로 달인\n",
      "울면 손 들 횡단보도 건너다 때 뛰다 치다 올 뻔 이범수 연기 드럽다 못 하다\n",
      "담백하다 깔끔하다 좋다 신 문 기 사 로만 보다 보다 자꾸 잊어버리다 그 들 사람 이다 것\n",
      "취향 존중 한 다지 진짜 내생 극장 보다 영화 중 가장 노잼 노 감동 임 스토리 어거지 감동 어거지\n",
      "ㄱ 냥 매번 긴장 되다 재밌다 ㅠㅠ\n",
      "차다 사람 들 웃기다 바스코 이기 락스 코 끄다 바비 이기 아이돌 깔다 그냥 끄다 안달 것 보이다\n",
      "굿바이 레닌 표절 것 이해 하다 왜 뒤 갈수록 재미 없어지다\n",
      "이 것 정말 깨알 캐스팅 질퍽 하 않다 산뜻하다 내 용구성 자다 버무러진 깨알 일드 ♥\n",
      "약탈 자 위 변명 이르다 저 놈 들 착하다 놈 들 절대 아니다 걸\n",
      "나름 심오하다 뜻 있다 듯 그냥 학생 선생 놀다 영화 절대 아니다\n",
      "보다 웃다 않다 건 불가능하다\n",
      "재미없다 지루하다 같다 음식 영화 도 바베트 만찬 넘다 차이나다 바베트 만찬 이야기 있다 음식 보다 재미 있다 이 것 볼 없다 음식 별로 안 나오다 핀란드 풍경 구 경 할랫 늘다 그것 별로 안 나오다 ㅡㅡ\n",
      "절대 평범하다 영화 아니다 수작 는걸 말씀드리다\n",
      "주제 좋다 중반 지루하다\n",
      "다 짤랐을꺼 그래서 납득 하다 수 없다 그렇다 꼭 그렇다 끄다\n",
      "kl 2 g 고추 털다 버리다 하다\n",
      "카밀라 벨 발연기\n",
      "재밌다 뎅\n",
      "센스 있다 연출 력 탁월하다 캐스팅 90년 대의 향수 그래서 9 점\n",
      "엄포스 위력 다시 한번 깨닫다 해주다 적 남 꽃 검사 님 연기 정말 좋다 완전 명품 드라마\n",
      "졸 쓰레기 진부하다 도안 돼다 ㅋㅋ 아 시간 아깝다\n",
      "재밌다 별 점 왜 이리 낮다\n",
      "1% 기대하다 내 죄인 이다 죄인 이다\n",
      "아직도 이 드라마 내 인생 최고\n",
      "패션 대한 열정 안나 윈 투어\n",
      "키이라 나이틀리 연기 하다 하다 대체 정신장애 이다 틱장애 이다\n",
      "허허 원작 정신 나가다 유령 재미있다\n",
      "포스터 있다 보이다 관객 114 명\n",
      "이 영화 왜 이렇게 저 평가 받다 모르다\n",
      "단순하다 은은하다 매력 영화\n",
      "다 알바생 내용 없다 무섭다 없다 웃기다 하나 없다 완전 별 싱겁다 영화 ㅇ ㅇ 내 ㅇ 시간 넘다 아깝다 움 완전 낚임\n",
      "오다 두다 서리 한 이 굶주리다\n",
      "정말 맘 들다 그래서 또 보다 또 보다 방법 없다 ㅜㅡ\n",
      "윤제문 멋지다 배우 발견 하다 돼다 소소하다 일 탈 잔잔하다 미소 먹음 하다 음악 조금 아쉽다 ㅠㅠ 8 점 주다 싶다 평점 올리다 싶다 10 점 주다\n",
      "평점 속지 말다 시간 낭비 돈 낭비 임\n",
      "리얼리티 뛰어나다 크다 공감 안 간다 이민기 캐릭터 정신의학 상 분노조절 장애 초기 증상 이다 툭하면 사람 패 욕 물건 파손 조금 오 바 이다 극 초반 신선하다 가면 갈수록 이민기 정신 상태 공감 불가\n",
      "마이너스 왜 없다 ㅋ 뮤비 보고 영화 수준 딱 알 하다 ㅉㅉ 북한 이렇다 만들다 돈 대다\n",
      "난 우리 영화 사랑 하다\n",
      "데 너 리스 타르 가르다 나다 용의 주인 되다 싶다 누 근친상간 하다 다니다 소설 속 제일 멋지다 놈 자 이 메 니스 터 이다 드라마 속 드래곤 용 이 제일 멋지다 웃음 감독 님 토르 2 다크 월드 말 잡수다 기본 선방 하다\n",
      "영화 사람 영혼 어루만지다 줄 수도 있다 거치다 세 상사 잠시 잊다 동화 같다 영화 행복하다\n",
      "야 세르게이 작다 고추 맵다 맛 보여주다 포퐁 저그 콩 진호 간다\n",
      "이렇게 가슴 시리 보다 드라마 또 있다 감동 그 자체\n",
      "난또 저 꼬마 애가 무슨 원한 깊다 하다 OO 그냥 혼자 나대다 OO 걸 어쩌라고\n",
      "재미있다\n",
      "전 좋다\n",
      "최고\n",
      "너무 충격 적다 기분 완전하다 푹 꺼지다 하다 느낌 활 력 하나 없다 너무나도 무겁다 지독하다 차갑다 무자비하다 그저 일본인 들 상상력 정말 대단하다 같다 생각 들다\n",
      "심심하다 영화\n",
      "백봉기 언제 나오다\n",
      "보다 그대로 들어맞다 예측 카리스마 없다 악역\n",
      "불알 나오다 당황 아무튼 영화 중간 끝나다 느낌\n",
      "평범하다 속 녹다 평범하다 일상 조금 밋밋하다 흠\n",
      "보다 계속 보다 전개도 느리다 주인공 은희 한두 컷 나오다 소 극적 모습 짜증 ㅜㅜ 맨날 언제 끝나다 기 대만 있다 전개 좀 빨리 빨리 ㅜㅜ\n",
      "사랑 싶다 가슴속 온 감정 헤집다 영화 정말 최고\n",
      "많다 사람 들 이 다큐 보고 우리나라 슬프다 현대 사의 하다 단면 대해 깊이 생각 사죄 바로 잡기 위해 노력 하다 하다 말로 듣다 보도 연맹 그 민간인 학살 이정 일 줄 이 것 명백하다 살인 이다 살인자 들 다 어디 있다\n",
      "예전 작품 캐릭터 에피소드 재탕 삼 탕 사골 우려 먹듯 우리 내용 산 가다 시청률 아예 안 나오다 이제 70회 중반인데 120 부작\n",
      "김남길 백 점 짜다 연기력 초반 몰입도 불구 지루하다 손예진 ㅈㅈ\n",
      "재밌다 비슷하다 영화 안 보다 분 들 늘다 재미있다 듯\n",
      "노래실력 뽑다 맞다 박시환 mama 나가다 진짜 망신\n",
      "아 일본 영화 다 이렇다 유치하다\n",
      "이틀 다 보다 재밌다 근데 차 안 물건 넣다 조작 하다 하다 차 안이 열리다 집 안이 활짝 열리다 아무나 들어가다 문자 조작 하다 비번 안 걸리다 ㅋㅋㅋ 그렇다 건 억지스럽다 그래도 내용 자체 좋다\n",
      "졸작\n",
      "재밌다 달팽이 빨 더 재밌다\n",
      "어설프다 전개 어이없다 결말\n",
      "부패하다 로마노프 왕조 기리 뭣같 영화 온몸 항거 하다 러시아 민중 들 그저 폭도\n",
      "내용 전개 무난 펴다 자다 보다\n",
      "매우 실망\n",
      "한국영 화 흥행 코드 갈등 갈등 계 속 갈등 화해 감동 평점 10 점 남발 흥행 뻔하다 뭐\n",
      "아햏햏 아햏햏 아햏햏\n",
      "뭐 시작 3분 만에 나오다 리플릿 사진 보다 불안하다\n",
      "단연 최고 하다\n",
      "감독 럼 먹다 영화 만들다 관객 뭘 말 하다 모르다 엉망 진창 개 진창\n",
      "이 것 뭐 우뢰매\n",
      "정말 쓰레기 영화 이다\n",
      "진정 위대하다 영화 최고 임\n",
      "별루 이다\n",
      "내일 기대 되다\n",
      "근데 조미 막문위 좋아하다 가요\n",
      "ㅋㅋㅋ 진짜 골깜 ㅋㅋ 눈 부라리다 때 쓰러지다 ㅋㅋ\n",
      "성룡 영화 중 최악 듯 ㅋㅋ\n",
      "골 때리다 ㅋㅋㅋ 걸스데이 이혜리 자다 되다\n",
      "서기 이쁘다\n",
      "완전 재밌다 ㅋㅋㅋ 백 인공 주귀 움 ㅋㅋㅋ\n",
      "인상 적 영화 이다\n",
      "어내스트 셀레스틴 완전 강추 정말 재밌다\n",
      "재미있다 영화 이다\n",
      "클라라 볼라 화신 보다 아니다\n",
      "진짜 보다 너무 슬프다 영화\n",
      "설정 재밌다 새롭다 에피소드 내 메인 스토리 차차 나오다 재밌다\n",
      "신카이 마코토 작화 밉다 유 하나 카나 연기 잘 해주다 더 대박 이다\n",
      "재미없다 진심 1 이훨 캐스팅 두 못 한 듯\n",
      "잔잔하다 생각 볼 만 영화 같다 ㅋ\n",
      "감독 님 들다 고은님 쓰다 영화 안 보다\n",
      "무섭다 않다 스토리 ㅡㅡ\n",
      "영화 속 억지스럽다 노골 적 술 광고 좀 은은하다 센스 있다 하다 어떻다\n",
      "킬링타임\n",
      "크리스마스 하다 떠오르다 영화\n",
      "재미있다 보다 매력 적 행복 요 ㅎㅎㅎ\n",
      "음악 완전하다 빠지다 볼 수 있다 영화 쫌 산만하다 하다\n",
      "태어나다 처음 영화 중간 나오다 불륜 로맨스\n",
      "왕 짜증 아주 전개 짬뽕 믹스 하다 음향 무섭다 하다 하아\n",
      "솔직하다 난 별루더 시간 낭비 느낌\n",
      "대박\n",
      "시청률 기준 되다 패널 가구 들 머 하다 명작 드라마 다 망치 ㅡㅡ 내 다 서운하다\n",
      "내용 이상하다\n",
      "몬스터 주식회사 3 D 재밌다 보다\n",
      "내용 전개 너무나 느리다\n",
      "소재 흥미 끌 이야기 전개 투 박하다 몰입 안되다\n",
      "절대 보다 쓰레기 영화\n",
      "중국인 특유 과장 허풍 있다 보이다 안간힘 쓸다 노력 가상하다 고증 현 실감 떨어지다 설정 거북 스럽다 도대체 그 들 왜 이렇게 스스로 과대 포장 하 것\n",
      "그냥 불법체류자 때리다 잡다 영화 좋다 무슨 우상화 만들다 미국 따뜻하다 설정 이 것 뭐임\n",
      "2년 의 삶속 주인공 생애 전부 드러나다 듯 하다\n",
      "별 점 10 점 가다\n",
      "별로\n",
      "보다 꽤 지난 후 남다 재미있다\n",
      "아니다 이 왜 9 점 대 이다\n",
      "10년 이 지나 다시 보다 되다 영화 다시 보다 그 순수하다 사랑 감동 ㅠㅠ 숀펜 연기 또한 甲\n",
      "올레 공짜 있다 보다 ㅋㅋ 헐다 스토리 문제 아니다 연기자 들 전혀 배역 어울리다 않다 그리고 상대 배우 들 다 따로 놓다 같다 이 것 연기자 들 문제 있다 보아 진심 완전 별로 임 라미란 아들 젤 볼 하다\n",
      "너무 욕심 많다 영화 어느 하다 쪽 제대로 보여주다\n",
      "아 빵점\n",
      "베댓 말 아주 잘쓰다\n",
      "아주 모자라다 않다\n",
      "영화 도둑 들 뫼비우스 하다 같다 나라 만들어지다 믿어지다\n",
      "온몸 찌릿 짜릿 나 용기 가다\n",
      "정말 재미있다 교훈 적 영 화이 네\n",
      "당시 상황 주제 주입 식이 아니다 긴장감 있다 재밌다 전하 작품\n",
      "케이블 그만 나오다 주다\n",
      "다르덴 이다 투 차이밍량 하나 안 섞이다 채 짬뽕 그릇 담기다\n",
      "여군 잼 없다 뭐 하다 건지다 ㅡㅡ 잼 없다 엠비씨 다 잼 없다 질린다 이제\n",
      "좋다\n",
      "한석규 김혜수 연기 돋보이다 영화 어디 모르다 많이 어설프다 영화\n",
      "솔직하다 에볼라 바이러스 떠들다 석 해 보다 되다 영화 작품 성 어떤 면 20 여 년전 영화 보기 믿다 힘들다 정도 정말 잘 만들다 보다 마지막 후반 부가 살짝 아쉽다 하지만 이 정도 수작 보다 시간 아깝다 않다 영화\n",
      "볼 만해\n",
      "재미있다 허풍 떨다 말다\n",
      "용가리 진짜 짱짱맨 ㅋ\n",
      "이 영화 이제 서다 보다 감히 내 인생 최고 영화 중 하나로 꼽 수 있다 작품 어떻다 살 야하다 나르다 위 고민 한번 더 하다 되다 시간 그리고 모건 프리 멀다 나이 들다 여전하다 섹시하다\n",
      "작가 별로 내 용이 진짜 별로 임 맨날 그냥 기대 재방송 하다 혹 시나 보다 답 없다 진짜\n",
      "명작 이렇다 명작 있다 싶다 보고 또 보다 여운 남다 영화\n",
      "아 진짜 조금 더 손 좀 보다 웬만하다 상업 영화 못 않다 퀄리티 쩔다 만들다 질 수 있다 아쉽다 그래도 충분하다 재미있다 개인 적 조금 더 잔인하다 더 자극 적 노출씬 화끈하다 하다 어떻다 하다 국산 영화 많이 아끼다 듯 보임\n",
      "그만 좀 끌 이제 끝내 지겹다 지겹다\n",
      "아\n",
      "역시 드니 의 연기 일품 나다 맥스 샘 죽이다 바랬다\n",
      "나름 괜찮다 작품 이다\n",
      "너무 좋다 영화\n",
      "정말 실망 스럽다\n",
      "배우 들 지네 들 안 뜨다 이런 영화 찍을껀데 왜 안 뜨다 진짜 모르다 면상 딱 보다 알다 왜 지네 자신 들 모르다\n",
      "어린이 좋아하다 내 어리다 적 동심 멀리 뜨다 낫다\n",
      "무술 인 왜 총을드\n",
      "10 점\n",
      "크리스토퍼 왈츠 타란티노 조합 ㅠㅠ\n",
      "한국 유명 한편 아니다 외국 상상 초월 유명하다 영화 이다\n",
      "오랜 만 재밌다 영화 보다\n",
      "종방 되어다 아쉽다 오늘 막 방도 잘 보다 방송 대본 꽤 완성 있다 느낌 받다 요즘 드라마 들 막장 지치다 수백향 정말 바른 드라마 이다 해 악역 들 그리다 심하다 어이없다 않다 MBC 화이팅\n",
      "평점 조절 위원회 나오다 웃음 김혜선 내일 오다 의 김 순정 순정 역할 제일 팜므파탈 로써 그 정도 잘 해내다 줄 정말 의외 이다 연기 20년 한 사람 요즘 사극 벌어지다 있다 그녀 대한 연 기 논란 왠지 코미디 한 장면 같다 웃음\n",
      "영화 끝 나가다 때 쯤 멍하다 다 보다 한마디 나오다 임 ㅈ 같다\n",
      "공유 존잘 ㅎㅎㅎ\n",
      "상쾌 발랄하다 영화 말 하다 껄끄런 성 소재 유쾌하다 해설 하다\n",
      "소파 죽 앉다 지키다 볼 이유 없다 작품\n",
      "로큰롤\n",
      "주된 타겟 어린이 일반 적 논리 통 하다 않다 건 알다 하지만 게임 흥미롭다 않다 요원 주인공 너무 무능력하다 별로 재미없다 CG 배경 거슬리다\n",
      "뮤지컬 영화 사운드 녹음 엉망 남다 춤 못 추다 내용 뻔하다 뻔 주인공 들 목소리 너무 안 어울리다 어제 CGV 뛰다 나가다 참다 진심 말리 싶다 영국 저 예산 DVD 용 영화 뮤지컬영화 아니다 맘마미아 1/10 도 안되다\n",
      "어리다 보다 꽤 좋아하다 로맨틱코미디\n",
      "게이물 줄 모르다 보다\n",
      "알바 끄다 저\n",
      "이 영화 머임 내 왜 받다 보다 그것 알고싶다 이 영화 배우 들 스텝 들 감독 꼭두각시 이다\n",
      "4 대다 2 최악\n",
      "정말 아름답다 영화 이다\n",
      "자극 적 것 익숙해지다 현대인 보다 눈 떼다 힘드다 연출 력\n",
      "뻑 뻑 자다 읽다 볼걸 나다 당하다\n",
      "정말 짜증 극치 보여주다 영화 굉장하다 언밸러스 느낌 뚱뚱하다 못 생기다 남자 애 발연기 시종일관 보다 고역 듯 간간히 흘러나오다 잔잔하다 클래식 풍 의 음악 듣기 싫다 짜증나다 정도 상당하다 싫다 영화\n",
      "감동 감동 ㅜㅜ 정말 최고 네\n",
      "별 점 주기도 아깝다 얼마나 내용 진부하다 욕 안 나오다 보고 재밌다 하다 사람 초딩 들 죄송하다 너무 화가 나서다 아무 것 볼 없다 보지 말다 그냥 티비 판 짜지다 한 거 같다\n",
      "나 왠만하다 짜증 알다\n",
      "돼지 피 먹다 닭목 따다 장면 우웩 역시 무당 아무나 하다 아니다\n",
      "버리다\n",
      "유치하다 지루하다 잠 오다\n",
      "3 류 풍 판타지 3 점 가져가다\n",
      "윤종신 복귀 좋다 이하늘 도대체 왜 뽑히다 알다 없다 참가자 실력 따다 전 심사 위원 인격 실력 쌓다 오다 어 하 어허 그만 좀 하다\n",
      "광장 작품 옛날 것 보고 싶다\n",
      "내 생 최고 영화\n",
      "어린시절 너무 무섭다 재미있다 보다 추억 판타지영화 절대 나쁘다 짓다 금물 지옥 가요\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m rdw:\n\u001b[1;32m----> 5\u001b[0m     malist \u001b[38;5;241m=\u001b[39m \u001b[43mtwitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     r \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m malist:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ddd\\lib\\site-packages\\konlpy\\tag\\_okt.py:71\u001b[0m, in \u001b[0;36mOkt.pos\u001b[1;34m(self, phrase, norm, stem, join)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"POS tagger.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03mIn contrast to other classes in this subpackage,\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03mthis POS tagger doesn't have a `flatten` option,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m:param join: If True, returns joined sets of morph and tag.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     69\u001b[0m validate_phrase_inputs(phrase)\n\u001b[1;32m---> 71\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjki\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mphrase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjpype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBoolean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjpype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBoolean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstem\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtoArray()\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m join:\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tokens]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "twitter = Okt()\n",
    "\n",
    "result = []\n",
    "for line in rdw:\n",
    "    malist = twitter.pos(line[1], norm=True, stem=True)\n",
    "    r = []\n",
    "    for word in malist:\n",
    "        if not word[1] in [\"Josa\", \"Eomi\", \"Punctuation\"]:\n",
    "\n",
    "           r.append(word[0])\n",
    "    rl = (\" \".join(r)).strip()\n",
    "    result.append(rl)\n",
    "    print(rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5d17127-80da-4d5b-980f-749c4f93e67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"NaverMovie.nlp\", 'w', encoding='utf-8') as fp:\n",
    "    fp.write(\"\\n\".join(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be33b4d3-a9e3-4053-944b-3d7dced0e419",
   "metadata": {},
   "outputs": [],
   "source": [
    "mData = word2vec.LineSentence(\"NaverMovie.nlp\")\n",
    "mModel = word2vec.Word2Vec(mData, vector_size=200, window=10, hs=1, min_count=2, sg=1)\n",
    "mModel.save(\"NaverMovie.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "788c8645-7b8e-4ec2-89d2-8d93975cafdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 제거 미적용: ['One', 'of', 'the', 'first', 'things', 'that', 'we', 'ask', 'ourselves', 'is', 'what', 'are', 'the', 'pros', 'and', 'cons', 'of', 'any', 'task', 'we', 'perform', '.'] \n",
      "\n",
      "불용어 제거 적용: ['One', 'first', 'things', 'ask', 'pros', 'cons', 'task', 'perform', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\516-29\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\516-29\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sample_text = \"One of the first things that we ask ourselves is what are the pros and cons of any task we perform.\"\n",
    "text_tokens = word_tokenize(sample_text)\n",
    "\n",
    "tokens_without_sw = [word for word in text_tokens if not word in stopwords.words('english')]\n",
    "\n",
    "print(\"불용어 제거 미적용:\", text_tokens, '\\n')\n",
    "print(\"불용어 제거 적용:\", tokens_without_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eac9737c-3727-4fef-a0c8-fa50c43c86f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obess obsses\n",
      "standard standard\n",
      "nation nation\n",
      "absent absent\n",
      "tribal tribalic\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "print(stemmer.stem('obesses'), stemmer.stem('obssesed'))\n",
    "print(stemmer.stem('standardizes'), stemmer.stem('standardization'))\n",
    "print(stemmer.stem('national'), stemmer.stem('nation'))\n",
    "print(stemmer.stem('absentness'), stemmer.stem('absently'))\n",
    "print(stemmer.stem('tribalical'), stemmer.stem('tribalicalized'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3dd97601-5715-45aa-89fe-aa9da7042683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obsess obsess\n",
      "standard standard\n",
      "nat nat\n",
      "abs abs\n",
      "trib trib\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "print(stemmer.stem('obsesses'), stemmer.stem('obsessed'))\n",
    "print(stemmer.stem('standardizes'), stemmer.stem('standardization'))\n",
    "print(stemmer.stem('national'), stemmer.stem('nation'))\n",
    "print(stemmer.stem('absentness'), stemmer.stem('absently'))\n",
    "print(stemmer.stem('tribalical'), stemmer.stem('tribalicalized'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7395e7fc-3749-465e-99a0-a7c8cc6b8bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\516-29\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obsess obsess\n",
      "standardizes standardization\n",
      "national nation\n",
      "absentness absently\n",
      "tribalical tribalicalized\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "print(stemmer.stem('obsesses'), stemmer.stem('obsessed'))\n",
    "print(lemma.lemmatize('standardizes'), lemma.lemmatize('standardization'))\n",
    "print(lemma.lemmatize('national'), lemma.lemmatize('nation'))\n",
    "print(lemma.lemmatize('absentness'), lemma.lemmatize('absently'))\n",
    "print(lemma.lemmatize('tribalical'), lemma.lemmatize('tribalicalized'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "64713693-01ec-48d1-b4f4-aa3330b931ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obsess obsessed\n",
      "standardize standardization\n",
      "national nation\n",
      "absentness absently\n",
      "tribalical tribalicalized\n"
     ]
    }
   ],
   "source": [
    "print(lemma.lemmatize('obsesses','v'), lemma.lemmatize('obsessed','a'))\n",
    "print(lemma.lemmatize('standardizes','v'), lemma.lemmatize('standardization','n'))\n",
    "print(lemma.lemmatize('national','a'), lemma.lemmatize('nation','n'))\n",
    "print(lemma.lemmatize('absentness','n'), lemma.lemmatize('absently','r'))\n",
    "print(lemma.lemmatize('tribalical','a'), lemma.lemmatize('tribalicalized','v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "041d7188-5dd4-4e34-9797-a674ec1b914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "29189b40-a1ee-48c9-91ee-1e3b80b36f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/516-29/deep/chap09/data/diabetes.csv')\n",
    "X = df[df.columns[:-1]]\n",
    "y = df['Outcome']\n",
    "\n",
    "X = X.values\n",
    "y = torch.tensor(y.values)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3b8faec5-4484-42fa-99eb-8666b321e7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = MinMaxScaler()\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.fit_transform(X_test)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "y_train = ms.fit_transform(y_train)\n",
    "y_test = ms.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ede69f06-f599-48d9-8655-9b69fd333a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customdataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.len = len(self.X)\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2efa6346-9dfd-4a18-987d-0c1db02407c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = customdataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
    "test_data = customdataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=train_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1e1b35a1-7d25-4ce5-881a-7677fff2681b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        self.layer_1 = nn.Linear(8, 64, bias=True)\n",
    "\n",
    "        self.layer_2 = nn.Linear(64, 64, bias=True)\n",
    "        self.layer_out = nn.Linear(64, 1, bias=True)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchorm1 = nn.BatchNorm1d(64)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a2c63e94-1b5f-4833-8c05-8522c402bbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binaryClassification(\n",
      "  (layer_1): Linear(in_features=8, out_features=64, bias=True)\n",
      "  (layer_2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (layer_out): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (batchorm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000+1\n",
    "print_epoch = 100\n",
    "LEARNING_RATE = 1e-2\n",
    "\n",
    "model = binaryClassification()\n",
    "model.to(device)\n",
    "print(model)\n",
    "BCE = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8826ac13-fffd-4737-8d55-11476a04e5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0b69ea61-b9fc-410e-bcab-7b8569e248a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'binaryClassification' object has no attribute 'batchnorm1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m      7\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m----> 8\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     loss \u001b[38;5;241m=\u001b[39m BCE(y_pred, y\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat())     \n\u001b[0;32m     11\u001b[0m     iteration_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ddd\\lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ddd\\lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[74], line 15\u001b[0m, in \u001b[0;36mbinaryClassification.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[0;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_1(inputs))\n\u001b[1;32m---> 15\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatchnorm1\u001b[49m(x)\n\u001b[0;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_2(x))\n\u001b[0;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatchnorm2(x)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ddd\\lib\\site-packages\\torch\\nn\\modules\\module.py:1962\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1960\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1961\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1962\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1963\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1964\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'binaryClassification' object has no attribute 'batchnorm1'"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):    \n",
    "    iteration_loss = 0.\n",
    "    iteration_accuracy = 0.\n",
    "    \n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        X, y = data\n",
    "        y_pred = model(X.float())\n",
    "        loss = BCE(y_pred, y.reshape(-1,1).float())     \n",
    "      \n",
    "        iteration_loss += loss\n",
    "        iteration_accuracy += accuracy(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if(epoch % print_epoch == 0):\n",
    "        print('Train: epoch: {0} - loss: {1:.5f}; acc: {2:.3f}'.format(epoch, iteration_loss/(i+1), iteration_accuracy/(i+1)))\n",
    "    \n",
    "    iteration_loss = 0.\n",
    "    iteration_accuracy = 0.\n",
    "    model.eval()\n",
    "    for i, data in enumerate(test_loader):\n",
    "        X, y = data\n",
    "        y_pred = model(X.float())\n",
    "        loss = BCE(y_pred, y.reshape(-1,1).float())\n",
    "        iteration_loss += loss\n",
    "        iteration_accuracy += accuracy(y_pred, y)\n",
    "    if(epoch % print_epoch == 0):\n",
    "        print('Test: epoch: {0} - loss: {1:.5f}; acc: {2:.3f}'.format(epoch, iteration_loss/(i+1), iteration_accuracy/(i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0433afe3-89d5-4bd9-b111-aa6e90f4d09c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
